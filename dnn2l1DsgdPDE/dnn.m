function Pfinal = dnn(beta, x,y, weights, biases, fun, eta, Niter)
    % dnn - trains deep neural network
    % x and y - input-output training set
    % weights and biases - the structure of the neural network, see rundnn
    %                      for details
    % fun - the choice of activation function
    % returns the final (trained) parameteres of the neural network
    
    %%%%%%%%% compute number of parameters 
    % nP - number of parameters
    nP = 0;
    for i = 1:size(weights)
        nP = nP + prod(weights(i,:)) + biases(i);
    end
    
    % generate initial random parameters
    rng(5000);
    
    Pzero = [4.9074
    4.3173
    4.5757
    3.3141
    3.4087
    4.9836
    4.9637
    5.2631
    4.8796
    4.9097
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
    1.0000
   -2.3618
   -3.6227
   -3.3459
   -4.9749
   -4.6930
   -1.4029
   -2.2396
   -0.5346
   -2.4268
   -2.3561
    1.8658
    0.0010
    2.1292
    1.8652
    1.6383
    1.7994
    2.3196
    1.8618
    1.8589
    2.3262
    1.8659
    0.2165
    2.1018
    1.8669
    1.5554
    1.8097
    2.2842
    1.8554
    1.8528
    2.1436
    1.8661
   -0.0449
    2.1046
    1.8668
    1.5620
    1.8089
    2.2885
    1.8558
    1.8533
    2.1622
    1.8685
    0.9374
    2.0822
    1.8695
    1.5322
    1.8157
    2.2573
    1.8513
    1.8490
    2.0660
    1.8684
    0.5502
    2.0843
    1.8694
    1.5354
    1.8153
    2.2601
    1.8517
    1.8494
    2.0724
    1.8313
   -0.0479
    2.1736
    1.8393
    1.7358
    1.7635
    2.3621
    1.8786
    1.8745
    2.4712
    1.8636
   -0.0959
    2.1329
    1.8634
    1.6470
    1.7968
    2.3235
    1.8631
    1.8600
    2.3409
    1.7877
   -0.3768
    2.2003
    1.8084
    1.8583
    1.7120
    2.3722
    1.8967
    1.8914
    2.6353
    1.8666
    0.0520
    2.1278
    1.8658
    1.6351
    1.8003
    2.3180
    1.8614
    1.8585
    2.3205
    1.8657
    0.0003
    2.1294
    1.8652
    1.6387
    1.7992
    2.3198
    1.8619
    1.8589
    2.3269
    0.5552
   -0.5602
    1.3745
    0.5389
    1.1259
    0.4916
    1.4350
    0.9708
    0.9519
    0.3792
   -0.3793
   -2.5301
    1.2378
   -0.2666
    1.2217
   -0.3019
    1.7824
    0.2355
    0.2140
   -0.9276
   -2];
    Pzero = 0.9 * randn(nP, 1);
    %Pzero = ones(nP,1);
    % train network / adjust parameters using gradient descent
    Pfinal = costfun(Pzero,beta, x, y, weights, biases, fun, eta, Niter);

end